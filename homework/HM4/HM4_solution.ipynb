{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: [Vivek Gupta]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "def to_one_hot(y, num_class=10):\n",
    "    return to_categorical(y)\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1,\n",
    "                 horizontal_flip=True)\n",
    "train_datagen.fit(x_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 552,362\n",
      "Trainable params: 551,466\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-3 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "  1/625 [..............................] - ETA: 0s - loss: 3.6243 - acc: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.0080s). Check your callbacks.\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 1.5132 - acc: 0.4477 - val_loss: 1.1978 - val_acc: 0.5580\n",
      "Epoch 2/15\n",
      "625/625 [==============================] - 7s 10ms/step - loss: 1.0451 - acc: 0.6255 - val_loss: 1.0847 - val_acc: 0.6221\n",
      "Epoch 3/15\n",
      "625/625 [==============================] - 7s 10ms/step - loss: 0.8930 - acc: 0.6838 - val_loss: 1.1945 - val_acc: 0.5904\n",
      "Epoch 4/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.7959 - acc: 0.7167 - val_loss: 0.8097 - val_acc: 0.7115\n",
      "Epoch 5/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.7363 - acc: 0.7416 - val_loss: 0.7520 - val_acc: 0.7326\n",
      "Epoch 6/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.6862 - acc: 0.7584 - val_loss: 0.7295 - val_acc: 0.7490\n",
      "Epoch 7/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.6463 - acc: 0.7760 - val_loss: 0.7288 - val_acc: 0.7581\n",
      "Epoch 8/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.6097 - acc: 0.7871 - val_loss: 0.6392 - val_acc: 0.7824\n",
      "Epoch 9/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.5835 - acc: 0.7990 - val_loss: 0.9197 - val_acc: 0.6973\n",
      "Epoch 10/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.5598 - acc: 0.8054 - val_loss: 0.6469 - val_acc: 0.7767\n",
      "Epoch 11/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.5369 - acc: 0.8151 - val_loss: 0.6114 - val_acc: 0.7950\n",
      "Epoch 12/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.5185 - acc: 0.8200 - val_loss: 0.5475 - val_acc: 0.8109\n",
      "Epoch 13/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.5006 - acc: 0.8270 - val_loss: 0.6621 - val_acc: 0.7832\n",
      "Epoch 14/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.4815 - acc: 0.8335 - val_loss: 0.5970 - val_acc: 0.8025\n",
      "Epoch 15/15\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.4682 - acc: 0.8382 - val_loss: 0.5502 - val_acc: 0.8160\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr, batch_size=64, epochs=15, validation_data=(x_val, y_val))\n",
    "# history = model.fit(train_datagen.flow(x_tr, y_tr, batch_size=64),\n",
    "#           steps_per_epoch=len(x_tr) / 64, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1,\n",
    "                 horizontal_flip=True)\n",
    "train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.4365 - acc: 0.8521\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.4213 - acc: 0.8566\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.4235 - acc: 0.8568\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.4126 - acc: 0.8598\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.4108 - acc: 0.8598\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3998 - acc: 0.8633\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3993 - acc: 0.8641\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3961 - acc: 0.8654\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3882 - acc: 0.8693\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3900 - acc: 0.8676\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3890 - acc: 0.8672\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3801 - acc: 0.8714\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3771 - acc: 0.8732\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3764 - acc: 0.8713\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3693 - acc: 0.8724\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train_vec, batch_size=64, epochs=15)\n",
    "# history = model.fit(train_datagen.flow(x_train, y_train_vec, batch_size=64),\n",
    "#           steps_per_epoch=len(x_tr) / 64, epochs=50, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5360 - acc: 0.8217\n",
      "loss = 0.5359965562820435\n",
      "accuracy = 0.8216999769210815\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
